{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"OC-FakeDect VAE Remake","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gU6tDeTCASMt","executionInfo":{"status":"ok","timestamp":1616698309646,"user_tz":0,"elapsed":1686,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"7ddf3f7a-5510-4f4f-b5ea-c77dcee4923e"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lqetwe06ASM7","executionInfo":{"status":"ok","timestamp":1616698316396,"user_tz":0,"elapsed":8400,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import BinaryCrossentropy\n","from keras import backend as K\n","\n","# !pip install -U keras-tuner\n","# from kerastuner.tuners import RandomSearch, Hyperband\n","# from kerastuner.engine.hypermodel import HyperModel\n","# from kerastuner.engine.hyperparameters import HyperParameters\n","# from kerastuner import Objective\n","\n","import Models.OCFakeDectVAE as OriginalOCFakeDectVAE"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dqaubd73ASM-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616698321441,"user_tz":0,"elapsed":13427,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"9e11d6de-8dbb-4f0f-bb1f-a65824b6583a"},"source":["# Check GPU available\n","%tensorflow_version 2.x\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZGWBPcE9ASNM","executionInfo":{"status":"ok","timestamp":1616698321442,"user_tz":0,"elapsed":13406,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 100, 100, 3\n","EPOCHS = 10\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 160\n","VALIDATION_SPLIT = 0.1\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd', 'avg'}\n","DF_TYPE = 'avg'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkC6WEcdASNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616698322117,"user_tz":0,"elapsed":14064,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"126fce81-367f-4e8e-99f8-5b50e7f4d04f"},"source":["# We are only using one class (OC), reals... But we test on reals and fakes\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-OC' \n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'input', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'input', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 5065 images belonging to 1 classes.\n","Found 562 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTUOyg8zWkg8","executionInfo":{"status":"ok","timestamp":1616698322655,"user_tz":0,"elapsed":14580,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Define callbacks e.g. Early Stopping\n","EARLY_STOP = EarlyStopping(monitor='reconstruction_loss',\n","                           patience=1,\n","                           mode='min',\n","                           verbose=1,\n","                           restore_best_weights=True)\n","\n","# Define Model OCFakeDect1\n","vae = OriginalOCFakeDectVAE.OCFakeDect1()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEZC9Nu5UiGT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616698405595,"user_tz":0,"elapsed":97504,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"0c79ced7-fa22-4ac8-a66e-8e0ffdbb4df4"},"source":["saved_weights = os.listdir(f'./Checkpoints/OGOCFakeDectVAE')\n","print(saved_weights)\n","vae.load_weights(f'./Checkpoints/OGOCFakeDectVAE/model_at_epoch_0')\n","vae.compile(optimizer=Adam())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['model_at_epoch_1.data-00000-of-00001', 'model_at_epoch_1.index', 'checkpoint']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iLYtSY4bnlhA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"65fecdb6-03f4-4a1f-f847-68c6738120a4"},"source":["# Trains for full epochs, also very slow (30 mins per epoch on OC)\n","STEPS = TRAIN_GENERATOR.n//BATCH_SIZE+1\n","for e in tqdm(range(EPOCHS)):\n","    for _ in tqdm(range(STEPS)):\n","        vae.fit(np.concatenate([TRAIN_GENERATOR.next()[0], VALIDATION_GENERATOR.next()[0]], axis=0),\n","                epochs=STEPS,\n","                batch_size=2*BATCH_SIZE,\n","                verbose=2,\n","                callbacks=[EARLY_STOP])\n","    # End of epoch, we save weights of model\n","    vae.save_weights(f'./Checkpoints/OGOCFakeDectVAE/model_at_epoch_{e}', save_format='tf')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]\n","  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/27\n","1/1 - 15s - loss: 6930.1382 - reconstruction_loss: 6920.6567 - kl_loss: 9.4814\n","Epoch 2/27\n","1/1 - 1s - loss: 6918.0293 - reconstruction_loss: 6867.7749 - kl_loss: 50.2546\n","Epoch 3/27\n","1/1 - 1s - loss: 6814.9268 - reconstruction_loss: 6814.0615 - kl_loss: 0.8650\n","Epoch 4/27\n","1/1 - 1s - loss: 6754.4829 - reconstruction_loss: 6754.4551 - kl_loss: 0.0279\n","Epoch 5/27\n","1/1 - 1s - loss: 6692.8940 - reconstruction_loss: 6692.8628 - kl_loss: 0.0311\n","Epoch 6/27\n","1/1 - 1s - loss: 6639.5674 - reconstruction_loss: 6639.5342 - kl_loss: 0.0332\n","Epoch 7/27\n","1/1 - 1s - loss: 6612.8813 - reconstruction_loss: 6612.7588 - kl_loss: 0.1224\n","Epoch 8/27\n","1/1 - 1s - loss: 6602.5063 - reconstruction_loss: 6601.6597 - kl_loss: 0.8469\n","Epoch 9/27\n","1/1 - 1s - loss: 6582.3438 - reconstruction_loss: 6576.9951 - kl_loss: 5.3489\n","Epoch 10/27\n","1/1 - 1s - loss: 6554.4351 - reconstruction_loss: 6533.8745 - kl_loss: 20.5605\n","Epoch 11/27\n","1/1 - 1s - loss: 6523.0635 - reconstruction_loss: 6511.5044 - kl_loss: 11.5589\n","Epoch 12/27\n","1/1 - 1s - loss: 6500.7031 - reconstruction_loss: 6494.9136 - kl_loss: 5.7897\n","Epoch 13/27\n","1/1 - 1s - loss: 6485.0107 - reconstruction_loss: 6481.5259 - kl_loss: 3.4847\n","Epoch 14/27\n","1/1 - 1s - loss: 6478.2925 - reconstruction_loss: 6475.5503 - kl_loss: 2.7422\n","Epoch 15/27\n","1/1 - 1s - loss: 6475.0308 - reconstruction_loss: 6472.1333 - kl_loss: 2.8975\n","Epoch 16/27\n","1/1 - 1s - loss: 6473.6460 - reconstruction_loss: 6469.9771 - kl_loss: 3.6690\n","Epoch 17/27\n","1/1 - 1s - loss: 6470.4175 - reconstruction_loss: 6465.5439 - kl_loss: 4.8735\n","Epoch 18/27\n","1/1 - 1s - loss: 6467.4209 - reconstruction_loss: 6460.7568 - kl_loss: 6.6640\n","Epoch 19/27\n","1/1 - 1s - loss: 6462.5830 - reconstruction_loss: 6453.3008 - kl_loss: 9.2820\n","Epoch 20/27\n","1/1 - 1s - loss: 6456.4697 - reconstruction_loss: 6443.5024 - kl_loss: 12.9672\n","Epoch 21/27\n","1/1 - 1s - loss: 6450.2627 - reconstruction_loss: 6432.2695 - kl_loss: 17.9931\n","Epoch 22/27\n","1/1 - 1s - loss: 6444.6475 - reconstruction_loss: 6416.3169 - kl_loss: 28.3306\n","Epoch 23/27\n","1/1 - 1s - loss: 6442.3618 - reconstruction_loss: 6414.5913 - kl_loss: 27.7706\n","Epoch 24/27\n","1/1 - 1s - loss: 6434.9927 - reconstruction_loss: 6390.4375 - kl_loss: 44.5551\n","Epoch 25/27\n","1/1 - 1s - loss: 6422.9556 - reconstruction_loss: 6389.3877 - kl_loss: 33.5677\n","Epoch 26/27\n","1/1 - 1s - loss: 6419.2446 - reconstruction_loss: 6388.6641 - kl_loss: 30.5805\n","Epoch 27/27\n","1/1 - 1s - loss: 6409.3320 - reconstruction_loss: 6367.9346 - kl_loss: 41.3973\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  4%|▎         | 1/27 [01:28<38:17, 88.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/27\n","1/1 - 1s - loss: 6366.2007 - reconstruction_loss: 6322.9395 - kl_loss: 43.2611\n","Epoch 2/27\n","1/1 - 1s - loss: 6355.4790 - reconstruction_loss: 6319.6978 - kl_loss: 35.7812\n","Epoch 3/27\n","1/1 - 1s - loss: 6343.4644 - reconstruction_loss: 6300.9067 - kl_loss: 42.5577\n","Epoch 4/27\n","1/1 - 1s - loss: 6337.4351 - reconstruction_loss: 6269.6162 - kl_loss: 67.8189\n","Epoch 5/27\n","1/1 - 1s - loss: 6332.7739 - reconstruction_loss: 6279.5425 - kl_loss: 53.2314\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/27 [01:40<27:18, 65.55s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00005: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6327.1548 - reconstruction_loss: 6269.0430 - kl_loss: 58.1116\n","Epoch 2/27\n","1/1 - 1s - loss: 6402.8857 - reconstruction_loss: 6253.6924 - kl_loss: 149.1935\n","Epoch 3/27\n","1/1 - 1s - loss: 6303.0068 - reconstruction_loss: 6232.9160 - kl_loss: 70.0908\n","Epoch 4/27\n","1/1 - 1s - loss: 6350.6924 - reconstruction_loss: 6299.9780 - kl_loss: 50.7145\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 11%|█         | 3/27 [01:50<19:32, 48.86s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00004: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6405.6938 - reconstruction_loss: 6352.8765 - kl_loss: 52.8175\n","Epoch 2/27\n","1/1 - 1s - loss: 6353.5566 - reconstruction_loss: 6282.4097 - kl_loss: 71.1469\n","Epoch 3/27\n","1/1 - 1s - loss: 6407.3481 - reconstruction_loss: 6306.3066 - kl_loss: 101.0416\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 15%|█▍        | 4/27 [01:57<13:57, 36.41s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00003: early stopping\n","Epoch 1/27\n","1/1 - 2s - loss: 6439.5361 - reconstruction_loss: 6338.0908 - kl_loss: 101.4453\n","Epoch 2/27\n","1/1 - 1s - loss: 6386.0723 - reconstruction_loss: 6337.0063 - kl_loss: 49.0659\n","Epoch 3/27\n","1/1 - 1s - loss: 6401.6162 - reconstruction_loss: 6370.6992 - kl_loss: 30.9168\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 19%|█▊        | 5/27 [02:05<10:12, 27.83s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00003: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6301.6938 - reconstruction_loss: 6272.8555 - kl_loss: 28.8386\n","Epoch 2/27\n","1/1 - 1s - loss: 6306.6855 - reconstruction_loss: 6275.5610 - kl_loss: 31.1245\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 22%|██▏       | 6/27 [02:10<07:19, 20.93s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00002: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6341.4355 - reconstruction_loss: 6309.0195 - kl_loss: 32.4161\n","Epoch 2/27\n","1/1 - 1s - loss: 6318.5898 - reconstruction_loss: 6275.5742 - kl_loss: 43.0156\n","Epoch 3/27\n","1/1 - 1s - loss: 6320.7905 - reconstruction_loss: 6258.8477 - kl_loss: 61.9429\n","Epoch 4/27\n","1/1 - 1s - loss: 6324.0566 - reconstruction_loss: 6244.9727 - kl_loss: 79.0839\n","Epoch 5/27\n","1/1 - 1s - loss: 6305.6230 - reconstruction_loss: 6225.6616 - kl_loss: 79.9616\n","Epoch 6/27\n","1/1 - 1s - loss: 6289.1772 - reconstruction_loss: 6217.3716 - kl_loss: 71.8058\n","Epoch 7/27\n","1/1 - 1s - loss: 6306.3823 - reconstruction_loss: 6239.4146 - kl_loss: 66.9676\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 26%|██▌       | 7/27 [02:47<08:35, 25.76s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00007: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6402.9829 - reconstruction_loss: 6335.4800 - kl_loss: 67.5027\n","Epoch 2/27\n","1/1 - 1s - loss: 6383.3521 - reconstruction_loss: 6294.4009 - kl_loss: 88.9513\n","Epoch 3/27\n","1/1 - 1s - loss: 6410.0562 - reconstruction_loss: 6301.0386 - kl_loss: 109.0177\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|██▉       | 8/27 [03:24<09:12, 29.10s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00003: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6353.2485 - reconstruction_loss: 6242.6284 - kl_loss: 110.6203\n","Epoch 2/27\n","1/1 - 1s - loss: 6306.0576 - reconstruction_loss: 6239.2720 - kl_loss: 66.7857\n","Epoch 3/27\n","1/1 - 1s - loss: 6371.2026 - reconstruction_loss: 6313.6382 - kl_loss: 57.5645\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 9/27 [03:41<07:38, 25.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00003: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6452.4751 - reconstruction_loss: 6399.6030 - kl_loss: 52.8722\n","Epoch 2/27\n","1/1 - 1s - loss: 6380.0225 - reconstruction_loss: 6327.0693 - kl_loss: 52.9532\n","Epoch 3/27\n","1/1 - 1s - loss: 6432.8608 - reconstruction_loss: 6362.2480 - kl_loss: 70.6129\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 10/27 [04:18<08:09, 28.81s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00003: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6408.4531 - reconstruction_loss: 6345.1089 - kl_loss: 63.3443\n","Epoch 2/27\n","1/1 - 1s - loss: 6391.3662 - reconstruction_loss: 6340.2144 - kl_loss: 51.1520\n","Epoch 3/27\n","1/1 - 1s - loss: 6377.1831 - reconstruction_loss: 6338.6353 - kl_loss: 38.5477\n","Epoch 4/27\n","1/1 - 1s - loss: 6376.6191 - reconstruction_loss: 6343.2876 - kl_loss: 33.3318\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 41%|████      | 11/27 [04:47<07:42, 28.88s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00004: early stopping\n","Epoch 1/27\n","1/1 - 1s - loss: 6316.1289 - reconstruction_loss: 6282.8999 - kl_loss: 33.2290\n","Epoch 2/27\n","1/1 - 1s - loss: 6314.9507 - reconstruction_loss: 6276.5918 - kl_loss: 38.3589\n","Epoch 3/27\n","1/1 - 1s - loss: 6303.3179 - reconstruction_loss: 6255.0698 - kl_loss: 48.2478\n","Epoch 4/27\n","1/1 - 1s - loss: 6293.8813 - reconstruction_loss: 6231.6973 - kl_loss: 62.1839\n","Epoch 5/27\n","1/1 - 1s - loss: 6285.9346 - reconstruction_loss: 6207.0874 - kl_loss: 78.8472\n","Epoch 6/27\n","1/1 - 1s - loss: 6284.9146 - reconstruction_loss: 6192.7280 - kl_loss: 92.1865\n","Epoch 7/27\n","1/1 - 1s - loss: 6277.7124 - reconstruction_loss: 6185.9097 - kl_loss: 91.8025\n","Epoch 8/27\n","1/1 - 1s - loss: 6269.7295 - reconstruction_loss: 6187.7236 - kl_loss: 82.0057\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 44%|████▍     | 12/27 [05:22<07:40, 30.70s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00008: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"igjOMUGwkdFs"},"source":["# Plot 5 images from test set\n","# for (x_train, _) in TRAIN_GENERATOR.next()[:5]:\n","#     X = np.expand_dims(x_train, axis=0)\n","#     Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","#     X_prime = vae.decoder.predict(Z)\n","#     face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","#     axes[0].imshow(X.squeeze())\n","#     axes[1].imshow(face)\n","#     fig.tight_layout()\n","\n","for (x_test, _) in VALIDATION_GENERATOR.next()[:5]:\n","    X = np.expand_dims(x_test, axis=0)\n","    Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","    X_prime = vae.decoder.predict(Z)\n","    face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","    axes[0].imshow(X.squeeze())\n","    axes[1].imshow(face)\n","    fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KlJGN8KyEBT"},"source":["# Re-define test generators for training the nerual net (since we are considering both classes now)\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30' \n","TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test' \n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'binary', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)\n","\n","TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0)\n","TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\n","                                                  batch_size = BATCH_SIZE,\n","                                                  class_mode = 'binary', \n","                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),                                \n","                                                  seed = DATA_GENERATOR_SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqxqDa7yI0Zw"},"source":["# Freeze the layers for the encoder, since now we will only train the dence layers at the end\n","for layer in vae.encoder.layers:\n","    layer.trainable = False\n","\n","# Add simple neural network at end of encoder (AFTER encoder(and decoder) has been trained on OC)\n","_, _, x = vae.encoder.output\n","x = layers.Flatten()(x)\n","x = layers.Dense(1, activation = 'sigmoid')(x)\n","\n","FC = Model(vae.encoder.input, x, name=\"FC\")\n","\n","FC.compile(optimizer = SGD(),\n","           loss = BinaryCrossentropy(),\n","           metrics = [metrics.BinaryAccuracy(name = 'acc'),\n","                      metrics.AUC(name = 'auc'),\n","                      metrics.FalsePositives(name = 'fp')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXilOj2gLOvh"},"source":["FC.fit(TRAIN_GENERATOR, \n","       steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size\n","       validation_data = VALIDATION_GENERATOR,\n","       validation_steps = TEST_GENERATOR.n//TEST_GENERATOR.batch_size,\n","       epochs=STEPS,\n","       batch_size=BATCH_SIZE, \n","       verbose=1,\n","       callbacks=[ModelCheckpoint(f'./Checkpoints/FC+OCFakeDectVAE/best_model',\n","                                  monitor='val_auc', \n","                                  mode='max'\n","                                  verbose=1, \n","                                  save_best_only=True)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohs32YdhOjrF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLE-Ww4Y37x2"},"source":["# # Load all training data, takes a very long time (3hrs)\n","# training_data = []\n","# for i in tqdm(range(TRAIN_GENERATOR.n//BATCH_SIZE+1)):\n","#     (x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), VALIDATION_GENERATOR.next()\n","#     training_data.extend(np.concatenate([x_train, x_test], axis=0)) \n","\n","# vae.fit(training_data,\n","#         epochs=100,\n","#         batch_size=2*BATCH_SIZE,\n","#         verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIrOs7aEqXMs"},"source":["# # VERY hacky test to see if the model is actually working\n","# # Purposefully overfit to a single batch of data and train for 1000 epochs on just that one batch\n","# (x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), VALIDATION_GENERATOR.next()\n","# training_data = np.concatenate([x_train, x_test], axis=0)\n","# vae.fit(training_data,\n","#         epochs=1000,\n","#         batch_size=2*BATCH_SIZE,\n","#         verbose=1)\n","\n","# for x in x_test[:10]:\n","#     X = np.expand_dims(x, axis=0)\n","#     Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","#     X_prime = vae.decoder.predict(Z)\n","#     face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","#     axes[0].imshow(X.squeeze())\n","#     axes[1].imshow(face)\n","#     fig.tight_layout()\n"],"execution_count":null,"outputs":[]}]}