{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Minimally Trained Baseline Tests","provenance":[{"file_id":"1UQUnqyHrzSZJr9H0Vi2mWUh-iQhbgTtv","timestamp":1617123690298}],"collapsed_sections":[],"authorship_tag":"ABX9TyP6zDoTxwfw41349ntqTTZF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"K7DxFXyRUNPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617129395613,"user_tz":-60,"elapsed":1622,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"99c2bf4b-3bf2-416e-9d47-f5b24ef59632"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7W8i8xxtURw5"},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import binary_crossentropy\n","from keras import backend as K\n","\n","try:\n","    import face_recognition\n","except ModuleNotFoundError:\n","    !pip install face_recognition\n","\n","from Util import pipeline\n","from Baseline.classifiers import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6iN8C_aMd6Q"},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 256, 256, 3\n","EPOCHS = 100\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 128\n","VALIDATION_SPLIT = 0.2\n","\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd', 'avg'}\n","DF_TYPE = 'avg'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNbLZGh6KuaX","executionInfo":{"status":"ok","timestamp":1617129399796,"user_tz":-60,"elapsed":5757,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"69e9dbc3-fb7c-447e-e5b1-c1cd27764073"},"source":["TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test'\n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'binary', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED,\n","                                                         follow_links = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 15711 images belonging to 2 classes.\n","Found 3927 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RUgnEKmYN59x"},"source":["# Train MesoInception4 w/ F2F weights\n","TEST_MODEL = MesoInception4().model\n","TEST_MODEL.compile(optimizer = TEST_MODEL.optimizer,\n","              loss = TEST_MODEL.loss,\n","              metrics = TEST_MODEL.metrics + [metrics.BinaryAccuracy(name = 'acc'),\n","                                              metrics.AUC(name = 'auc'),\n","                                              metrics.FalsePositives(name = 'fp')])\n","WEIGHTS_PATH = './Baseline/weights/MesoInception_F2F.h5'\n","TEST_MODEL.load_weights(WEIGHTS_PATH) \n","\n","# Make last layer trainable\n","for layer in TEST_MODEL.layers:\n","    layer.trainable = False\n","TEST_MODEL.layers[-1].trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSV3Re8PGJ85"},"source":["train_gen_list = list(TRAIN_GENERATOR.classes)\n","val_gen_list = list(VALIDATION_GENERATOR.classes)\n","\n","train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\n","val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\n","\n","pos = train_pos + val_pos\n","neg = train_neg + val_neg\n","total = pos + neg\n","\n","weight_for_0 = (1 / neg)*(total)/2.0 \n","weight_for_1 = (1 / pos)*(total)/2.0\n","\n","CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\n","\n","EARLY_STOP = EarlyStopping(monitor='val_auc',\n","                           patience=1,\n","                           mode='max',\n","                           verbose=1,\n","                           restore_best_weights=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZvkfABWIasv","outputId":"7b762351-1411-49e4-f31b-26fac4e56356"},"source":["HISTORY = TEST_MODEL.fit(TRAIN_GENERATOR,\n","                         steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size,\n","                         validation_data = VALIDATION_GENERATOR,\n","                         validation_steps = VALIDATION_GENERATOR.n//VALIDATION_GENERATOR.batch_size,\n","                         epochs = EPOCHS,\n","                         verbose = 1,\n","                         class_weight = CLASS_WEIGHT,\n","                         callbacks = [EARLY_STOP])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","122/122 [==============================] - 4014s 33s/step - loss: 0.3011 - acc: 0.6014 - auc: 0.5267 - fp: 306.3171 - val_loss: 0.2237 - val_acc: 0.6326 - val_auc: 0.6874 - val_fp: 112.0000\n","Epoch 2/100\n","122/122 [==============================] - ETA: 0s - loss: 0.2108 - acc: 0.6429 - auc: 0.7306 - fp: 204.1475"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XJlk_ffzViKP"},"source":["weight_name = WEIGHTS_PATH.split('_')[-1]\n","pipeline.evaluate_model(TEST_MODEL = TEST_MODEL),\n","                        EXPERIMENT_NAME = f'Minimally Trained MesoInception4 on {DF_TYPE} w/ {weight_name}',\n","                        TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test',\n","                        HISTORY = HISTORY)"],"execution_count":null,"outputs":[]}]}