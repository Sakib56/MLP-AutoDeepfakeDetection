{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"colab":{"name":"OC-FakeDect VAE Remake","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gU6tDeTCASMt","executionInfo":{"status":"ok","timestamp":1615998240258,"user_tz":0,"elapsed":51750,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"ceb10870-9c47-4dd5-c3a8-9758440431db"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lqetwe06ASM7","executionInfo":{"status":"ok","timestamp":1615998249840,"user_tz":0,"elapsed":3691,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import binary_crossentropy\n","from keras import backend as K\n","\n","# !pip install -U keras-tuner\n","# from kerastuner.tuners import RandomSearch, Hyperband\n","# from kerastuner.engine.hypermodel import HyperModel\n","# from kerastuner.engine.hyperparameters import HyperParameters\n","# from kerastuner import Objective"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dqaubd73ASM-","executionInfo":{"status":"ok","timestamp":1615998258094,"user_tz":0,"elapsed":5892,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"9b4c1eb4-fdad-4ff1-a02d-935752769477"},"source":["# Check GPU available\n","%tensorflow_version 2.x\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGWBPcE9ASNM","executionInfo":{"status":"ok","timestamp":1616003169360,"user_tz":0,"elapsed":626,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"de92482d-1b2f-4abe-969f-a4a60e15b90b"},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 28, 28, 3\n","EPOCHS = 300\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 128\n","VALIDATION_SPLIT = 0.1\n","LEARNING_RATE = 1e-3\n","LATENT_DIM = 1600\n","\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd-30', 'avg-30'}\n","DF_TYPE = 'avg-30'\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}'\n","TEST_DIR = f'{TRAIN_VAL_DIR}-test'\n","\n","# TRAIN_VAL_DIR += '/Celeb-real'\n","# TEST_DIR += '/Celeb-real'\n","\n","TRAIN_VAL_DIR, TEST_DIR"],"execution_count":185,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('./Celeb-DF-v2/Celeb-avg-30', './Celeb-DF-v2/Celeb-avg-30-test')"]},"metadata":{"tags":[]},"execution_count":185}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkC6WEcdASNV","executionInfo":{"status":"ok","timestamp":1616003175721,"user_tz":0,"elapsed":4363,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"79722912-1cca-4dee-c918-82acd0b1a6a0"},"source":["TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'binary', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)\n","\n","TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0)\n","TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\n","                                                  batch_size = BATCH_SIZE,\n","                                                  class_mode = 'binary', \n","                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),                                \n","                                                  seed = DATA_GENERATOR_SEED)\n","\n"],"execution_count":186,"outputs":[{"output_type":"stream","text":["Found 49942 images belonging to 2 classes.\n","Found 5548 images belonging to 2 classes.\n","Found 19638 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FsZWbjtnASNO","executionInfo":{"status":"ok","timestamp":1616002253798,"user_tz":0,"elapsed":8040,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Random sampling function for latent vector, z; \"variational part\"\n","class Sampling(layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","    \n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ZTdI0O3AfQO","executionInfo":{"status":"ok","timestamp":1616002253800,"user_tz":0,"elapsed":8031,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# # Encoder\r\n","\r\n","# encoder_inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\r\n","# # 100x100x3\r\n","\r\n","# x = layers.Conv2D(16, 3, strides=1, padding=\"same\")(encoder_inputs)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 100x100x16\r\n","\r\n","# x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 50x50x32\r\n","\r\n","# x = layers.Conv2D(64, 3, strides=1, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 50x50x64\r\n","\r\n","# x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 25x25x32\r\n","\r\n","# x = layers.Flatten()(x)\r\n","# # 20000\r\n","\r\n","# # Sampling\r\n","# z_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\r\n","# z_log_var = layers.Dense(LATENT_DIM, name=\"z_log_var\")(x)\r\n","# z = Sampling()([z_mean, z_log_var])\r\n","# # 1600\r\n","\r\n","# # Defining full encoder as keras model\r\n","# encoder = keras.Model(encoder_inputs, \r\n","#                       [z_mean, z_log_var, z], \r\n","#                       name=\"encoder\")"],"execution_count":141,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7SCkjomASNP","executionInfo":{"status":"ok","timestamp":1616002253801,"user_tz":0,"elapsed":8022,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# # Decoder\n","# latent_inputs = keras.Input(shape=(LATENT_DIM,))\n","\n","# x = layers.Dense(LATENT_DIM)(latent_inputs)\n","# x = layers.Reshape((5, 5, 64))(x)\n","# # 1600\n","\n","# x = layers.Conv2DTranspose(32, 3, strides=5, padding=\"same\")(x)\n","# x = layers.BatchNormalization(axis = 1)(x)\n","# x = layers.Activation('relu')(x)\n","# # 25x25x32\n","\n","# x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\")(x)\n","# x = layers.BatchNormalization(axis = 1)(x)\n","# x = layers.Activation('relu')(x)\n","# # 50x50x64\n","\n","# x = layers.Conv2DTranspose(32, 3, strides=1, padding=\"same\")(x)\n","# x = layers.BatchNormalization(axis = 1)(x)\n","# x = layers.Activation('relu')(x)\n","# # 50x50x32\n","\n","# x = layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\")(x)\n","# x = layers.BatchNormalization(axis = 1)(x)\n","# x = layers.Activation('relu')(x)\n","# # 100x100x16\n","\n","# x = layers.Conv2DTranspose(3, 3, strides=1, padding=\"same\")(x)\n","# x = layers.BatchNormalization(axis = 1)(x)\n","# x = layers.Activation('sigmoid')(x)\n","# decoder_outputs = x\n","# # 100x100x3\n","\n","# # Defining full decoder as keras model\n","# decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"],"execution_count":142,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xvcadHBbF0v"},"source":["encoder = Sequential([\r\n","    Convolution2D(64, (3, 3), padding = 'same', input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    Convolution2D(64, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    AveragePooling2D(),\r\n","    Convolution2D(128, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    Convolution2D(128, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    AveragePooling2D(),\r\n","    Flatten(),\r\n","    Dense(128),\r\n","    BatchNormalization(),\r\n","    Activation('relu'),\r\n","    Dense(encoding_size),\r\n","    Activation('tanh')\r\n","])\r\n","\r\n","sampling = Sequential([Dense(49, input_shape = (encoding_size,)),\r\n","                       MySampling(),\r\n","                       BatchNormalization(),\r\n","                       Activation('relu')\r\n","])\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kgT50NRNO4Lu","executionInfo":{"status":"ok","timestamp":1616002486733,"user_tz":0,"elapsed":819,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"79dbb431-a53f-43c0-d345-550910b22c73"},"source":["# Encoder\r\n","\r\n","encoder_inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\r\n","# 128x128x3\r\n","\r\n","x = layers.Conv2D(16, 3, strides=1, padding=\"same\")(encoder_inputs)\r\n","x = layers.BatchNormalization(axis = 1)(x)\r\n","x = layers.Activation('relu')(x)\r\n","# 128x128x16\r\n","\r\n","x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\r\n","x = layers.BatchNormalization(axis = 1)(x)\r\n","x = layers.Activation('relu')(x)\r\n","# 64x64x32\r\n","\r\n","x = layers.Conv2D(64, 3, strides=1, padding=\"same\")(x)\r\n","x = layers.BatchNormalization(axis = 1)(x)\r\n","x = layers.Activation('relu')(x)\r\n","# 64x64x64\r\n","\r\n","x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\r\n","x = layers.BatchNormalization(axis = 1)(x)\r\n","x = layers.Activation('relu')(x)\r\n","# 32x32x64\r\n","\r\n","x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\r\n","x = layers.BatchNormalization(axis = 1)(x)\r\n","x = layers.Activation('relu')(x)\r\n","# 16x16x64\r\n","\r\n","x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\r\n","x = layers.BatchNormalization(axis = 1)(x)\r\n","x = layers.Activation('relu')(x)\r\n","x\r\n","\r\n","# x = layers.Flatten()(x)\r\n","# # 20000\r\n","\r\n","# # Sampling\r\n","# z_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\r\n","# z_log_var = layers.Dense(LATENT_DIM, name=\"z_log_var\")(x)\r\n","# z = Sampling()([z_mean, z_log_var])\r\n","# # 1600\r\n","\r\n","# # Defining full encoder as keras model\r\n","# encoder = keras.Model(encoder_inputs, \r\n","#                       [z_mean, z_log_var, z], \r\n","#                       name=\"encoder\")"],"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 8, 8, 128) dtype=float32 (created by layer 'activation_238')>"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"MwEj-AoJO8LU"},"source":["# Decoder\r\n","decoder = Sequential([\r\n","    Dense(49, input_shape = (encoding_size,)),\r\n","    BatchNormalization(),\r\n","    Activation('relu'),\r\n","    Reshape((7, 7, 1)),\r\n","    Convolution2D(128, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    Convolution2D(128, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    UpSampling2D(),\r\n","    Convolution2D(64, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    Convolution2D(64, (3, 3), padding = 'same'),\r\n","    BatchNormalization(axis = 1),\r\n","    Activation('relu'),\r\n","    UpSampling2D(),\r\n","    Convolution2D(3, (3, 3), padding = 'same', activation = 'tanh')\r\n","])\r\n","# latent_inputs = keras.Input(shape=(LATENT_DIM,))\r\n","\r\n","# x = layers.Dense(LATENT_DIM)(latent_inputs)\r\n","# x = layers.Reshape((5, 5, 64))(x)\r\n","# # 1600\r\n","\r\n","# x = layers.Conv2DTranspose(32, 3, strides=5, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 25x25x32\r\n","\r\n","# x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 50x50x64\r\n","\r\n","# x = layers.Conv2DTranspose(32, 3, strides=1, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 50x50x32\r\n","\r\n","# x = layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('relu')(x)\r\n","# # 100x100x16\r\n","\r\n","# x = layers.Conv2DTranspose(3, 3, strides=1, padding=\"same\")(x)\r\n","# x = layers.BatchNormalization(axis = 1)(x)\r\n","# x = layers.Activation('sigmoid')(x)\r\n","# decoder_outputs = x\r\n","# # 100x100x3\r\n","\r\n","# # Defining full decoder as keras model\r\n","# decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQKsEyroASNS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616001793827,"user_tz":0,"elapsed":3501,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"4ed706da-4a28-4316-f863-daa505ab4dec"},"source":["# VAE summary\n","encoder.summary()\n","decoder.summary()"],"execution_count":129,"outputs":[{"output_type":"stream","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_63 (InputLayer)           [(None, 100, 100, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_126 (Conv2D)             (None, 100, 100, 16) 448         input_63[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_158 (BatchN (None, 100, 100, 16) 400         conv2d_126[0][0]                 \n","__________________________________________________________________________________________________\n","activation_156 (Activation)     (None, 100, 100, 16) 0           batch_normalization_158[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_127 (Conv2D)             (None, 50, 50, 32)   4640        activation_156[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_159 (BatchN (None, 50, 50, 32)   200         conv2d_127[0][0]                 \n","__________________________________________________________________________________________________\n","activation_157 (Activation)     (None, 50, 50, 32)   0           batch_normalization_159[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_128 (Conv2D)             (None, 50, 50, 64)   18496       activation_157[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_160 (BatchN (None, 50, 50, 64)   200         conv2d_128[0][0]                 \n","__________________________________________________________________________________________________\n","activation_158 (Activation)     (None, 50, 50, 64)   0           batch_normalization_160[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_129 (Conv2D)             (None, 25, 25, 32)   18464       activation_158[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_161 (BatchN (None, 25, 25, 32)   100         conv2d_129[0][0]                 \n","__________________________________________________________________________________________________\n","activation_159 (Activation)     (None, 25, 25, 32)   0           batch_normalization_161[0][0]    \n","__________________________________________________________________________________________________\n","flatten_22 (Flatten)            (None, 20000)        0           activation_159[0][0]             \n","__________________________________________________________________________________________________\n","z_mean (Dense)                  (None, 1600)         32001600    flatten_22[0][0]                 \n","__________________________________________________________________________________________________\n","z_log_var (Dense)               (None, 1600)         32001600    flatten_22[0][0]                 \n","__________________________________________________________________________________________________\n","sampling_14 (Sampling)          (None, 1600)         0           z_mean[0][0]                     \n","                                                                 z_log_var[0][0]                  \n","==================================================================================================\n","Total params: 64,046,148\n","Trainable params: 64,045,698\n","Non-trainable params: 450\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_67 (InputLayer)        [(None, 1600)]            0         \n","_________________________________________________________________\n","dense_35 (Dense)             (None, 1600)              2561600   \n","_________________________________________________________________\n","reshape_32 (Reshape)         (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_transpose_52 (Conv2DT (None, 25, 25, 32)        18464     \n","_________________________________________________________________\n","batch_normalization_176 (Bat (None, 25, 25, 32)        100       \n","_________________________________________________________________\n","activation_174 (Activation)  (None, 25, 25, 32)        0         \n","_________________________________________________________________\n","conv2d_transpose_53 (Conv2DT (None, 50, 50, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_177 (Bat (None, 50, 50, 64)        200       \n","_________________________________________________________________\n","activation_175 (Activation)  (None, 50, 50, 64)        0         \n","_________________________________________________________________\n","conv2d_transpose_54 (Conv2DT (None, 50, 50, 32)        18464     \n","_________________________________________________________________\n","batch_normalization_178 (Bat (None, 50, 50, 32)        200       \n","_________________________________________________________________\n","activation_176 (Activation)  (None, 50, 50, 32)        0         \n","_________________________________________________________________\n","conv2d_transpose_55 (Conv2DT (None, 100, 100, 16)      4624      \n","_________________________________________________________________\n","batch_normalization_179 (Bat (None, 100, 100, 16)      400       \n","_________________________________________________________________\n","activation_177 (Activation)  (None, 100, 100, 16)      0         \n","_________________________________________________________________\n","conv2d_transpose_56 (Conv2DT (None, 100, 100, 3)       435       \n","_________________________________________________________________\n","batch_normalization_180 (Bat (None, 100, 100, 3)       400       \n","_________________________________________________________________\n","activation_178 (Activation)  (None, 100, 100, 3)       0         \n","=================================================================\n","Total params: 2,623,383\n","Trainable params: 2,622,733\n","Non-trainable params: 650\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9i3HH_uZASNT","executionInfo":{"status":"ok","timestamp":1616001814664,"user_tz":0,"elapsed":894,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Build VAE model as custom (keras model class) class\n","class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n","        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.total_loss_tracker,\n","                self.reconstruction_loss_tracker,\n","                self.kl_loss_tracker]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            \n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(binary_crossentropy(data, reconstruction),\n","                              axis=(1, 2)))\n","            \n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","            \n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        \n","        return {\"loss\": self.total_loss_tracker.result(),\n","                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","                \"kl_loss\": self.kl_loss_tracker.result()}"],"execution_count":130,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lvQuWrXTZ09","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616001988101,"user_tz":0,"elapsed":71510,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"98c45502-4eaa-49d3-ff85-d71a635004a7"},"source":["vae = VAE(encoder, decoder)\r\n","vae.compile(optimizer=keras.optimizers.Adam())\r\n","\r\n","(x_train, _) = TRAIN_GENERATOR.next()\r\n","(x_test, _) = VALIDATION_GENERATOR.next()\r\n","training_data = np.concatenate([x_train, x_test], axis=0)\r\n","training_data = np.expand_dims(training_data, -1).astype(\"float32\") / 255\r\n","training_data = training_data[:, :, :, :, 0]\r\n","\r\n","vae.fit(training_data,\r\n","        epochs=100,\r\n","        batch_size=BATCH_SIZE)"],"execution_count":132,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","2/2 [==============================] - 3s 368ms/step - loss: 117.3972 - reconstruction_loss: 115.1968 - kl_loss: 2.7996\n","Epoch 2/100\n","2/2 [==============================] - 1s 347ms/step - loss: 120.1180 - reconstruction_loss: 115.3078 - kl_loss: 3.6223\n","Epoch 3/100\n","2/2 [==============================] - 1s 342ms/step - loss: 118.3375 - reconstruction_loss: 114.1579 - kl_loss: 3.6935\n","Epoch 4/100\n","2/2 [==============================] - 1s 344ms/step - loss: 117.4119 - reconstruction_loss: 114.0985 - kl_loss: 3.0357\n","Epoch 5/100\n","2/2 [==============================] - 1s 337ms/step - loss: 117.8244 - reconstruction_loss: 114.4015 - kl_loss: 2.5090\n","Epoch 6/100\n","2/2 [==============================] - 1s 343ms/step - loss: 115.8291 - reconstruction_loss: 113.5046 - kl_loss: 2.5308\n","Epoch 7/100\n","2/2 [==============================] - 1s 341ms/step - loss: 116.1485 - reconstruction_loss: 113.4798 - kl_loss: 2.8234\n","Epoch 8/100\n","2/2 [==============================] - 1s 335ms/step - loss: 115.9186 - reconstruction_loss: 112.7849 - kl_loss: 3.2767\n","Epoch 9/100\n","2/2 [==============================] - 1s 340ms/step - loss: 115.2278 - reconstruction_loss: 112.6221 - kl_loss: 2.9303\n","Epoch 10/100\n","2/2 [==============================] - 1s 335ms/step - loss: 114.9399 - reconstruction_loss: 112.8059 - kl_loss: 2.2693\n","Epoch 11/100\n","2/2 [==============================] - 1s 338ms/step - loss: 115.7781 - reconstruction_loss: 113.6776 - kl_loss: 2.0540\n","Epoch 12/100\n","2/2 [==============================] - 1s 338ms/step - loss: 114.5128 - reconstruction_loss: 112.4066 - kl_loss: 2.3358\n","Epoch 13/100\n","2/2 [==============================] - 1s 335ms/step - loss: 115.0607 - reconstruction_loss: 112.1548 - kl_loss: 2.6976\n","Epoch 14/100\n","2/2 [==============================] - 1s 333ms/step - loss: 115.4540 - reconstruction_loss: 112.0178 - kl_loss: 2.9012\n","Epoch 15/100\n","2/2 [==============================] - 1s 339ms/step - loss: 114.8627 - reconstruction_loss: 111.7065 - kl_loss: 2.7840\n","Epoch 16/100\n","2/2 [==============================] - 1s 339ms/step - loss: 114.5383 - reconstruction_loss: 111.6434 - kl_loss: 2.3987\n","Epoch 17/100\n","2/2 [==============================] - 1s 338ms/step - loss: 113.6967 - reconstruction_loss: 111.5618 - kl_loss: 1.9578\n","Epoch 18/100\n","2/2 [==============================] - 1s 341ms/step - loss: 113.3415 - reconstruction_loss: 112.1314 - kl_loss: 1.7194\n","Epoch 19/100\n","2/2 [==============================] - 1s 338ms/step - loss: 114.4505 - reconstruction_loss: 112.1999 - kl_loss: 1.9035\n","Epoch 20/100\n","2/2 [==============================] - 1s 338ms/step - loss: 113.7446 - reconstruction_loss: 111.0937 - kl_loss: 2.2924\n","Epoch 21/100\n","2/2 [==============================] - 1s 340ms/step - loss: 113.5594 - reconstruction_loss: 111.2452 - kl_loss: 2.2466\n","Epoch 22/100\n","2/2 [==============================] - 1s 340ms/step - loss: 112.6963 - reconstruction_loss: 111.2861 - kl_loss: 1.8448\n","Epoch 23/100\n","2/2 [==============================] - 1s 337ms/step - loss: 113.5726 - reconstruction_loss: 111.6677 - kl_loss: 1.5053\n","Epoch 24/100\n","2/2 [==============================] - 1s 337ms/step - loss: 113.3022 - reconstruction_loss: 111.5016 - kl_loss: 1.4683\n","Epoch 25/100\n","2/2 [==============================] - 1s 337ms/step - loss: 113.2834 - reconstruction_loss: 111.7623 - kl_loss: 1.6075\n","Epoch 26/100\n","2/2 [==============================] - 1s 338ms/step - loss: 112.9634 - reconstruction_loss: 110.9156 - kl_loss: 1.9207\n","Epoch 27/100\n","2/2 [==============================] - 1s 340ms/step - loss: 114.0796 - reconstruction_loss: 111.1789 - kl_loss: 1.9922\n","Epoch 28/100\n","2/2 [==============================] - 1s 342ms/step - loss: 113.1269 - reconstruction_loss: 110.8552 - kl_loss: 1.7849\n","Epoch 29/100\n","2/2 [==============================] - 1s 342ms/step - loss: 112.2256 - reconstruction_loss: 111.2381 - kl_loss: 1.3977\n","Epoch 30/100\n","2/2 [==============================] - 1s 342ms/step - loss: 111.6100 - reconstruction_loss: 111.3106 - kl_loss: 1.1121\n","Epoch 31/100\n","2/2 [==============================] - 1s 336ms/step - loss: 111.8896 - reconstruction_loss: 111.2995 - kl_loss: 0.9698\n","Epoch 32/100\n","2/2 [==============================] - 1s 338ms/step - loss: 111.8970 - reconstruction_loss: 111.2733 - kl_loss: 0.9081\n","Epoch 33/100\n","2/2 [==============================] - 1s 338ms/step - loss: 111.5831 - reconstruction_loss: 111.0384 - kl_loss: 0.8690\n","Epoch 34/100\n","2/2 [==============================] - 1s 340ms/step - loss: 111.3157 - reconstruction_loss: 110.8829 - kl_loss: 0.7847\n","Epoch 35/100\n","2/2 [==============================] - 1s 336ms/step - loss: 111.6984 - reconstruction_loss: 110.8302 - kl_loss: 0.6481\n","Epoch 36/100\n","2/2 [==============================] - 1s 339ms/step - loss: 111.4766 - reconstruction_loss: 110.8565 - kl_loss: 0.4919\n","Epoch 37/100\n","2/2 [==============================] - 1s 338ms/step - loss: 111.8967 - reconstruction_loss: 110.8423 - kl_loss: 0.3531\n","Epoch 38/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.8892 - reconstruction_loss: 110.7414 - kl_loss: 0.2434\n","Epoch 39/100\n","2/2 [==============================] - 1s 335ms/step - loss: 110.6857 - reconstruction_loss: 110.6976 - kl_loss: 0.1616\n","Epoch 40/100\n","2/2 [==============================] - 1s 342ms/step - loss: 111.1803 - reconstruction_loss: 110.6523 - kl_loss: 0.1030\n","Epoch 41/100\n","2/2 [==============================] - 1s 342ms/step - loss: 110.3587 - reconstruction_loss: 110.6037 - kl_loss: 0.0630\n","Epoch 42/100\n","2/2 [==============================] - 1s 336ms/step - loss: 110.2740 - reconstruction_loss: 110.4822 - kl_loss: 0.0461\n","Epoch 43/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.8289 - reconstruction_loss: 110.4549 - kl_loss: 0.0402\n","Epoch 44/100\n","2/2 [==============================] - 1s 338ms/step - loss: 109.7695 - reconstruction_loss: 110.3736 - kl_loss: 0.0355\n","Epoch 45/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.3068 - reconstruction_loss: 110.3804 - kl_loss: 0.0316\n","Epoch 46/100\n","2/2 [==============================] - 1s 343ms/step - loss: 110.5790 - reconstruction_loss: 110.3087 - kl_loss: 0.0278\n","Epoch 47/100\n","2/2 [==============================] - 1s 341ms/step - loss: 110.5798 - reconstruction_loss: 110.3121 - kl_loss: 0.0239\n","Epoch 48/100\n","2/2 [==============================] - 1s 339ms/step - loss: 109.6770 - reconstruction_loss: 110.2497 - kl_loss: 0.0200\n","Epoch 49/100\n","2/2 [==============================] - 1s 341ms/step - loss: 110.5769 - reconstruction_loss: 110.2205 - kl_loss: 0.0164\n","Epoch 50/100\n","2/2 [==============================] - 1s 337ms/step - loss: 110.3349 - reconstruction_loss: 110.2134 - kl_loss: 0.0132\n","Epoch 51/100\n","2/2 [==============================] - 1s 334ms/step - loss: 110.1999 - reconstruction_loss: 110.1765 - kl_loss: 0.0103\n","Epoch 52/100\n","2/2 [==============================] - 1s 339ms/step - loss: 110.2360 - reconstruction_loss: 110.1866 - kl_loss: 0.0078\n","Epoch 53/100\n","2/2 [==============================] - 1s 332ms/step - loss: 109.6918 - reconstruction_loss: 110.1552 - kl_loss: 0.0056\n","Epoch 54/100\n","2/2 [==============================] - 1s 340ms/step - loss: 110.5161 - reconstruction_loss: 110.1590 - kl_loss: 0.0040\n","Epoch 55/100\n","2/2 [==============================] - 1s 341ms/step - loss: 109.1784 - reconstruction_loss: 110.2085 - kl_loss: 0.0028\n","Epoch 56/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.0768 - reconstruction_loss: 110.1535 - kl_loss: 0.0017\n","Epoch 57/100\n","2/2 [==============================] - 1s 339ms/step - loss: 110.2728 - reconstruction_loss: 110.1201 - kl_loss: 6.6490e-04\n","Epoch 58/100\n","2/2 [==============================] - 1s 341ms/step - loss: 110.3888 - reconstruction_loss: 110.1108 - kl_loss: 1.9208e-04\n","Epoch 59/100\n","2/2 [==============================] - 1s 340ms/step - loss: 109.4373 - reconstruction_loss: 110.1258 - kl_loss: 1.5302e-04\n","Epoch 60/100\n","2/2 [==============================] - 1s 337ms/step - loss: 109.6093 - reconstruction_loss: 110.0724 - kl_loss: 1.8020e-04\n","Epoch 61/100\n","2/2 [==============================] - 1s 340ms/step - loss: 110.0139 - reconstruction_loss: 110.0868 - kl_loss: 1.9668e-04\n","Epoch 62/100\n","2/2 [==============================] - 1s 337ms/step - loss: 110.2207 - reconstruction_loss: 110.0765 - kl_loss: 1.8115e-04\n","Epoch 63/100\n","2/2 [==============================] - 1s 340ms/step - loss: 110.2660 - reconstruction_loss: 110.0574 - kl_loss: 1.8096e-04\n","Epoch 64/100\n","2/2 [==============================] - 1s 338ms/step - loss: 109.6224 - reconstruction_loss: 110.0785 - kl_loss: 1.5943e-04\n","Epoch 65/100\n","2/2 [==============================] - 1s 341ms/step - loss: 109.0312 - reconstruction_loss: 110.0477 - kl_loss: 1.2577e-04\n","Epoch 66/100\n","2/2 [==============================] - 1s 341ms/step - loss: 110.4554 - reconstruction_loss: 110.0225 - kl_loss: 1.4983e-04\n","Epoch 67/100\n","2/2 [==============================] - 1s 340ms/step - loss: 110.7448 - reconstruction_loss: 110.0489 - kl_loss: 1.2498e-04\n","Epoch 68/100\n","2/2 [==============================] - 1s 331ms/step - loss: 110.6500 - reconstruction_loss: 110.0183 - kl_loss: 8.8468e-05\n","Epoch 69/100\n","2/2 [==============================] - 1s 342ms/step - loss: 110.3509 - reconstruction_loss: 110.0105 - kl_loss: 6.9603e-05\n","Epoch 70/100\n","2/2 [==============================] - 1s 338ms/step - loss: 108.9527 - reconstruction_loss: 110.0341 - kl_loss: 7.3850e-05\n","Epoch 71/100\n","2/2 [==============================] - 1s 332ms/step - loss: 109.8614 - reconstruction_loss: 110.0314 - kl_loss: 1.0039e-04\n","Epoch 72/100\n","2/2 [==============================] - 1s 337ms/step - loss: 110.1385 - reconstruction_loss: 110.0150 - kl_loss: 1.2906e-04\n","Epoch 73/100\n","2/2 [==============================] - 1s 335ms/step - loss: 109.4994 - reconstruction_loss: 110.0134 - kl_loss: 1.4378e-04\n","Epoch 74/100\n","2/2 [==============================] - 1s 335ms/step - loss: 110.1066 - reconstruction_loss: 110.0085 - kl_loss: 1.2192e-04\n","Epoch 75/100\n","2/2 [==============================] - 1s 340ms/step - loss: 110.3270 - reconstruction_loss: 110.0186 - kl_loss: 9.0972e-05\n","Epoch 76/100\n","2/2 [==============================] - 1s 337ms/step - loss: 110.1391 - reconstruction_loss: 110.0007 - kl_loss: 5.9351e-05\n","Epoch 77/100\n","2/2 [==============================] - 1s 338ms/step - loss: 109.7544 - reconstruction_loss: 110.0070 - kl_loss: 5.0336e-05\n","Epoch 78/100\n","2/2 [==============================] - 1s 337ms/step - loss: 110.1522 - reconstruction_loss: 110.0057 - kl_loss: 4.6909e-05\n","Epoch 79/100\n","2/2 [==============================] - 1s 340ms/step - loss: 110.3322 - reconstruction_loss: 109.9881 - kl_loss: 4.7907e-05\n","Epoch 80/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.2792 - reconstruction_loss: 109.9889 - kl_loss: 5.8219e-05\n","Epoch 81/100\n","2/2 [==============================] - 1s 348ms/step - loss: 109.5078 - reconstruction_loss: 110.0137 - kl_loss: 6.9693e-05\n","Epoch 82/100\n","2/2 [==============================] - 1s 334ms/step - loss: 109.3773 - reconstruction_loss: 109.9957 - kl_loss: 6.3226e-05\n","Epoch 83/100\n","2/2 [==============================] - 1s 338ms/step - loss: 109.9530 - reconstruction_loss: 109.9796 - kl_loss: 6.0067e-05\n","Epoch 84/100\n","2/2 [==============================] - 1s 341ms/step - loss: 110.3784 - reconstruction_loss: 109.9921 - kl_loss: 4.9889e-05\n","Epoch 85/100\n","2/2 [==============================] - 1s 339ms/step - loss: 111.0981 - reconstruction_loss: 109.9931 - kl_loss: 3.7476e-05\n","Epoch 86/100\n","2/2 [==============================] - 1s 334ms/step - loss: 110.2333 - reconstruction_loss: 109.9969 - kl_loss: 3.1278e-05\n","Epoch 87/100\n","2/2 [==============================] - 1s 341ms/step - loss: 109.8201 - reconstruction_loss: 109.9891 - kl_loss: 2.8238e-05\n","Epoch 88/100\n","2/2 [==============================] - 1s 341ms/step - loss: 110.2864 - reconstruction_loss: 109.9837 - kl_loss: 2.7388e-05\n","Epoch 89/100\n","2/2 [==============================] - 1s 335ms/step - loss: 109.5995 - reconstruction_loss: 109.9851 - kl_loss: 2.6807e-05\n","Epoch 90/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.1932 - reconstruction_loss: 109.9874 - kl_loss: 2.8461e-05\n","Epoch 91/100\n","2/2 [==============================] - 1s 341ms/step - loss: 109.9506 - reconstruction_loss: 109.9745 - kl_loss: 3.5375e-05\n","Epoch 92/100\n","2/2 [==============================] - 1s 335ms/step - loss: 110.1921 - reconstruction_loss: 109.9785 - kl_loss: 4.3184e-05\n","Epoch 93/100\n","2/2 [==============================] - 1s 335ms/step - loss: 109.7385 - reconstruction_loss: 109.9952 - kl_loss: 4.8682e-05\n","Epoch 94/100\n","2/2 [==============================] - 1s 338ms/step - loss: 110.4492 - reconstruction_loss: 110.0045 - kl_loss: 4.1634e-05\n","Epoch 95/100\n","2/2 [==============================] - 1s 335ms/step - loss: 110.0710 - reconstruction_loss: 110.0075 - kl_loss: 3.3975e-05\n","Epoch 96/100\n","2/2 [==============================] - 1s 338ms/step - loss: 109.9685 - reconstruction_loss: 109.9843 - kl_loss: 3.3185e-05\n","Epoch 97/100\n","2/2 [==============================] - 1s 339ms/step - loss: 109.6951 - reconstruction_loss: 110.0035 - kl_loss: 3.1367e-05\n","Epoch 98/100\n","2/2 [==============================] - 1s 337ms/step - loss: 110.2231 - reconstruction_loss: 109.9992 - kl_loss: 3.3349e-05\n","Epoch 99/100\n","2/2 [==============================] - 1s 335ms/step - loss: 109.8913 - reconstruction_loss: 109.9935 - kl_loss: 2.7999e-05\n","Epoch 100/100\n","2/2 [==============================] - 1s 335ms/step - loss: 109.7107 - reconstruction_loss: 109.9717 - kl_loss: 2.8342e-05\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fefd0e84d10>"]},"metadata":{"tags":[]},"execution_count":132}]},{"cell_type":"code","metadata":{"id":"igjOMUGwkdFs","colab":{"base_uri":"https://localhost:8080/","height":745},"executionInfo":{"status":"error","timestamp":1616005277687,"user_tz":0,"elapsed":620,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"81958120-4b00-4561-adfb-cc6e7c4271d6"},"source":["# X = np.expand_dims(x_test[0], axis=0)\r\n","\r\n","# plt.figure()\r\n","# plt.imshow(X.squeeze())\r\n","# Z = vae.encoder.predict(X)\r\n","# for z in Z:\r\n","#     X_primed = vae.decoder.predict(z)\r\n","#     face = X_primed.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\r\n","#     face = np.array(face*255*225, dtype=np.uint8)\r\n","    \r\n","#     plt.figure()\r\n","#     plt.imshow(face)\r\n","\r\n","%matplotlib inline\r\n","\r\n","for x in x_test[:10]:\r\n","    X = np.expand_dims(x, axis=0)\r\n","    Z = vae.encoder.predict(X)[0]\r\n","\r\n","    X_prime = vae.decoder.predict(Z)\r\n","    face = X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\r\n","    face = np.array(face*255, dtype=np.uint8)\r\n","\r\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 3))\r\n","    axes[0].imshow(X.squeeze())\r\n","    axes[1].imshow(face)\r\n","    fig.tight_layout()"],"execution_count":244,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-244-b82e706f1326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mX_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer encoder: expected shape=(None, 100, 100, 3), found shape=(None, 28, 28, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"HjGDdNVX8efl","executionInfo":{"status":"ok","timestamp":1616002634541,"user_tz":0,"elapsed":930,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["import numpy             as np\r\n","import matplotlib.pyplot as plt\r\n","import keras.backend     as K\r\n","\r\n","from keras.models       import Sequential\r\n","from keras.layers       import Dense\r\n","from keras.layers       import BatchNormalization\r\n","from keras.layers       import Reshape\r\n","from keras.layers       import UpSampling2D\r\n","from keras.layers       import Convolution2D\r\n","from keras.layers       import Activation\r\n","from keras.layers       import Flatten\r\n","from keras.layers       import AveragePooling2D\r\n","from keras.optimizers   import Adam\r\n","from keras.datasets     import mnist"],"execution_count":162,"outputs":[]}]}