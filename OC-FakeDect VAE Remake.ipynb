{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"OC-FakeDect VAE Remake","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gU6tDeTCASMt","executionInfo":{"status":"ok","timestamp":1616695974628,"user_tz":0,"elapsed":2010,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"45ecb94e-453d-4ec3-9dd3-fc20122be701"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lqetwe06ASM7","executionInfo":{"status":"ok","timestamp":1616695976691,"user_tz":0,"elapsed":4060,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import BinaryCrossentropy\n","from keras import backend as K\n","\n","# !pip install -U keras-tuner\n","# from kerastuner.tuners import RandomSearch, Hyperband\n","# from kerastuner.engine.hypermodel import HyperModel\n","# from kerastuner.engine.hyperparameters import HyperParameters\n","# from kerastuner import Objective\n","\n","import Models.OCFakeDectVAE as OriginalOCFakeDectVAE"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dqaubd73ASM-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616695977208,"user_tz":0,"elapsed":4573,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"d075ecf9-e762-4c27-a486-9cffbef1696a"},"source":["# Check GPU available\n","%tensorflow_version 2.x\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZGWBPcE9ASNM","executionInfo":{"status":"ok","timestamp":1616695977221,"user_tz":0,"elapsed":4576,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 100, 100, 3\n","EPOCHS = 10\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 192\n","VALIDATION_SPLIT = 0.1\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd', 'avg'}\n","DF_TYPE = 'avg'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkC6WEcdASNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616695977227,"user_tz":0,"elapsed":4576,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"019f8e35-4eba-4a69-cc1e-60cefdf6b463"},"source":["# We are only using one class (OC), reals... But we test on reals and fakes\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-OC' \n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'input', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'input', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 5065 images belonging to 1 classes.\n","Found 562 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTUOyg8zWkg8","executionInfo":{"status":"ok","timestamp":1616695977705,"user_tz":0,"elapsed":5048,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Define callbacks e.g. Early Stopping\n","EARLY_STOP = EarlyStopping(monitor='reconstruction_loss',\n","                           patience=1,\n","                           mode='min',\n","                           verbose=1,\n","                           restore_best_weights=True)\n","\n","# Define Model OCFakeDect1\n","vae = OriginalOCFakeDectVAE.OCFakeDect1()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEZC9Nu5UiGT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616695977707,"user_tz":0,"elapsed":5045,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"1ecde0c8-e883-46a4-f03e-14014ec21450"},"source":["weights = os.listdir(f'./Checkpoints/OGOCFakeDectVAE')\n","print(weights)\n","# latest_weights = f'./Checkpoints/OGOCFakeDectVAE/{weights[-1]}'\n","# vae.load_weights(f\"./Checkpoints/OGOCFakeDectVAE/{latest_weights}\")\n","# print(f'loading {latest_weights}')\n","# vae = keras.models.load_model(latest_weights)\n","vae.compile(optimizer=Adam())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['weights_at_epoch_0.h5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iLYtSY4bnlhA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2fcfb200-c36b-4840-ceb8-9877d6873ad1"},"source":["# Trains for full epochs, also very slow (30 mins per epoch on OC)\n","\n","STEPS = TRAIN_GENERATOR.n//BATCH_SIZE+1\n","for e in tqdm(range(EPOCHS)):\n","    for _ in tqdm(range(STEPS)):\n","        vae.fit(np.concatenate([TRAIN_GENERATOR.next()[0], VALIDATION_GENERATOR.next()[0]], axis=0),\n","                epochs=STEPS,\n","                batch_size=2*BATCH_SIZE,\n","                verbose=1,\n","                callbacks=[EARLY_STOP])\n","    # End of epoch, we save weights of model\n","    vae.save(f'./Checkpoints/OGOCFakeDectVAE/model_at_epoch_{e}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]\n","  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/27\n","1/1 [==============================] - 8s 8s/step - loss: 6928.9888 - reconstruction_loss: 6919.6641 - kl_loss: 9.3248\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6914.2617 - reconstruction_loss: 6865.1274 - kl_loss: 49.1341\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6810.4653 - reconstruction_loss: 6809.5688 - kl_loss: 0.8967\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6748.2773 - reconstruction_loss: 6748.2583 - kl_loss: 0.0192\n","Epoch 5/27\n","1/1 [==============================] - 1s 1s/step - loss: 6684.2803 - reconstruction_loss: 6684.2578 - kl_loss: 0.0223\n","Epoch 6/27\n","1/1 [==============================] - 1s 1s/step - loss: 6629.2915 - reconstruction_loss: 6629.2539 - kl_loss: 0.0374\n","Epoch 7/27\n","1/1 [==============================] - 1s 1s/step - loss: 6599.9116 - reconstruction_loss: 6599.7461 - kl_loss: 0.1655\n","Epoch 8/27\n","1/1 [==============================] - 1s 1s/step - loss: 6591.9307 - reconstruction_loss: 6590.7993 - kl_loss: 1.1315\n","Epoch 9/27\n","1/1 [==============================] - 1s 1s/step - loss: 6571.4678 - reconstruction_loss: 6565.2441 - kl_loss: 6.2235\n","Epoch 10/27\n","1/1 [==============================] - 1s 1s/step - loss: 6542.4609 - reconstruction_loss: 6522.8716 - kl_loss: 19.5892\n","Epoch 11/27\n","1/1 [==============================] - 1s 1s/step - loss: 6511.1602 - reconstruction_loss: 6498.5933 - kl_loss: 12.5670\n","Epoch 12/27\n","1/1 [==============================] - 1s 1s/step - loss: 6487.1221 - reconstruction_loss: 6480.6909 - kl_loss: 6.4310\n","Epoch 13/27\n","1/1 [==============================] - 1s 1s/step - loss: 6470.7466 - reconstruction_loss: 6466.8965 - kl_loss: 3.8500\n","Epoch 14/27\n","1/1 [==============================] - 1s 1s/step - loss: 6461.8989 - reconstruction_loss: 6458.9399 - kl_loss: 2.9588\n","Epoch 15/27\n","1/1 [==============================] - 1s 1s/step - loss: 6457.7847 - reconstruction_loss: 6454.7661 - kl_loss: 3.0186\n","Epoch 16/27\n","1/1 [==============================] - 1s 1s/step - loss: 6455.4473 - reconstruction_loss: 6451.6372 - kl_loss: 3.8102\n","Epoch 17/27\n","1/1 [==============================] - 1s 1s/step - loss: 6453.9351 - reconstruction_loss: 6448.5933 - kl_loss: 5.3418\n","Epoch 18/27\n","1/1 [==============================] - 1s 1s/step - loss: 6451.7715 - reconstruction_loss: 6444.1890 - kl_loss: 7.5827\n","Epoch 19/27\n","1/1 [==============================] - 1s 1s/step - loss: 6446.1240 - reconstruction_loss: 6435.7202 - kl_loss: 10.4036\n","Epoch 20/27\n","1/1 [==============================] - 1s 1s/step - loss: 6441.1694 - reconstruction_loss: 6427.3457 - kl_loss: 13.8235\n","Epoch 21/27\n","1/1 [==============================] - 1s 1s/step - loss: 6434.6597 - reconstruction_loss: 6416.5181 - kl_loss: 18.1417\n","Epoch 22/27\n","1/1 [==============================] - 1s 1s/step - loss: 6427.1411 - reconstruction_loss: 6401.6616 - kl_loss: 25.4793\n","Epoch 23/27\n","1/1 [==============================] - 1s 1s/step - loss: 6426.1504 - reconstruction_loss: 6397.8979 - kl_loss: 28.2524\n","Epoch 24/27\n","1/1 [==============================] - 1s 1s/step - loss: 6421.1704 - reconstruction_loss: 6375.0386 - kl_loss: 46.1319\n","Epoch 25/27\n","1/1 [==============================] - 1s 1s/step - loss: 6404.6636 - reconstruction_loss: 6372.5591 - kl_loss: 32.1047\n","Epoch 26/27\n","1/1 [==============================] - 1s 1s/step - loss: 6403.2148 - reconstruction_loss: 6372.5723 - kl_loss: 30.6426\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  4%|▎         | 1/27 [01:33<40:37, 93.73s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00026: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6379.9648 - reconstruction_loss: 6350.4609 - kl_loss: 29.5041\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6383.1748 - reconstruction_loss: 6325.8315 - kl_loss: 57.3431\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6363.8423 - reconstruction_loss: 6317.8872 - kl_loss: 45.9551\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6360.4521 - reconstruction_loss: 6327.6406 - kl_loss: 32.8114\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/27 [01:46<28:55, 69.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00004: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 5s 5s/step - loss: 6430.0942 - reconstruction_loss: 6394.2417 - kl_loss: 35.8525\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6412.1470 - reconstruction_loss: 6355.9893 - kl_loss: 56.1576\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6414.1060 - reconstruction_loss: 6335.9189 - kl_loss: 78.1869\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6394.1675 - reconstruction_loss: 6335.8140 - kl_loss: 58.3534\n","Epoch 5/27\n","1/1 [==============================] - 1s 1s/step - loss: 6396.7881 - reconstruction_loss: 6346.6128 - kl_loss: 50.1751\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 11%|█         | 3/27 [02:04<21:38, 54.10s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00005: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6312.4429 - reconstruction_loss: 6266.5845 - kl_loss: 45.8582\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6318.1626 - reconstruction_loss: 6246.0293 - kl_loss: 72.1333\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6298.3091 - reconstruction_loss: 6228.4858 - kl_loss: 69.8234\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6295.5547 - reconstruction_loss: 6234.5073 - kl_loss: 61.0471\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 15%|█▍        | 4/27 [02:16<15:52, 41.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00004: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6333.4526 - reconstruction_loss: 6266.8521 - kl_loss: 66.6005\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6318.8760 - reconstruction_loss: 6235.4336 - kl_loss: 83.4423\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6317.9263 - reconstruction_loss: 6232.3755 - kl_loss: 85.5507\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6305.3657 - reconstruction_loss: 6244.8237 - kl_loss: 60.5418\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 19%|█▊        | 5/27 [02:28<11:55, 32.54s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00004: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6411.9194 - reconstruction_loss: 6350.1021 - kl_loss: 61.8174\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6397.4771 - reconstruction_loss: 6327.0649 - kl_loss: 70.4123\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6395.7407 - reconstruction_loss: 6313.6021 - kl_loss: 82.1385\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6389.0200 - reconstruction_loss: 6319.7769 - kl_loss: 69.2430\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 22%|██▏       | 6/27 [02:40<09:12, 26.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00004: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6343.2759 - reconstruction_loss: 6274.9673 - kl_loss: 68.3084\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6333.4976 - reconstruction_loss: 6270.2134 - kl_loss: 63.2841\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6334.2734 - reconstruction_loss: 6265.6431 - kl_loss: 68.6302\n","Epoch 4/27\n","1/1 [==============================] - 1s 1s/step - loss: 6326.3413 - reconstruction_loss: 6247.8398 - kl_loss: 78.5015\n","Epoch 5/27\n","1/1 [==============================] - 1s 1s/step - loss: 6320.1406 - reconstruction_loss: 6242.0254 - kl_loss: 78.1151\n","Epoch 6/27\n","1/1 [==============================] - 1s 1s/step - loss: 6316.4097 - reconstruction_loss: 6238.2563 - kl_loss: 78.1531\n","Epoch 7/27\n","1/1 [==============================] - 1s 1s/step - loss: 6311.3574 - reconstruction_loss: 6232.1704 - kl_loss: 79.1871\n","Epoch 8/27\n","1/1 [==============================] - 1s 1s/step - loss: 6308.1440 - reconstruction_loss: 6226.2056 - kl_loss: 81.9385\n","Epoch 9/27\n","1/1 [==============================] - 1s 1s/step - loss: 6320.6646 - reconstruction_loss: 6233.9751 - kl_loss: 86.6897\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 26%|██▌       | 7/27 [03:06<08:46, 26.33s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00009: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6311.6992 - reconstruction_loss: 6229.2593 - kl_loss: 82.4402\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 7260.6689 - reconstruction_loss: 7046.7930 - kl_loss: 213.8759\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|██▉       | 8/27 [03:12<06:24, 20.24s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00002: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 7275.9824 - reconstruction_loss: 7062.5864 - kl_loss: 213.3960\n","Epoch 2/27\n","1/1 [==============================] - 1s 1s/step - loss: 6531.0938 - reconstruction_loss: 6392.9966 - kl_loss: 138.0973\n","Epoch 3/27\n","1/1 [==============================] - 1s 1s/step - loss: 6886.7417 - reconstruction_loss: 6616.4468 - kl_loss: 270.2947\n","Restoring model weights from the end of the best epoch.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 9/27 [03:21<05:02, 16.83s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 00003: early stopping\n","Epoch 1/27\n","1/1 [==============================] - 1s 1s/step - loss: 6840.5981 - reconstruction_loss: 6585.0513 - kl_loss: 255.5469\n","Epoch 2/27\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"igjOMUGwkdFs"},"source":["# Plot 5 images from test set\n","(x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), \n","\n","# for (x, _) in TRAIN_GENERATOR.next()[:5]:\n","#     X = np.expand_dims(x, axis=0)\n","#     Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","#     X_prime = vae.decoder.predict(Z)\n","#     face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","#     axes[0].imshow(X.squeeze())\n","#     axes[1].imshow(face)\n","#     fig.tight_layout()\n","\n","for (x, _) in VALIDATION_GENERATOR.next()[:5]:\n","    X = np.expand_dims(x, axis=0)\n","    Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","    X_prime = vae.decoder.predict(Z)\n","    face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","    axes[0].imshow(X.squeeze())\n","    axes[1].imshow(face)\n","    fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KlJGN8KyEBT"},"source":["# Re-define test generators for training the nerual net (since we are considering both classes now)\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30' \n","TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test' \n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'binary', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)\n","\n","TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0)\n","TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\n","                                                  batch_size = BATCH_SIZE,\n","                                                  class_mode = 'binary', \n","                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),                                \n","                                                  seed = DATA_GENERATOR_SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqxqDa7yI0Zw"},"source":["# Freeze the layers for the encoder, since now we will only train the dence layers at the end\n","for layer in vae.encoder.layers:\n","    layer.trainable = False\n","\n","# Add simple neural network at end of encoder (AFTER encoder(and decoder) has been trained on OC)\n","_, _, x = vae.encoder.output\n","x = layers.Flatten()(x)\n","x = layers.Dense(1, activation = 'sigmoid')(x)\n","\n","FC = Model(vae.encoder.input, x, name=\"FC\")\n","\n","FC.compile(optimizer = SGD(),\n","           loss = BinaryCrossentropy(),\n","           metrics = [metrics.BinaryAccuracy(name = 'acc'),\n","                      metrics.AUC(name = 'auc'),\n","                      metrics.FalsePositives(name = 'fp')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXilOj2gLOvh"},"source":["FC.fit(TRAIN_GENERATOR, \n","       steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size\n","       validation_data = VALIDATION_GENERATOR,\n","       validation_steps = TEST_GENERATOR.n//TEST_GENERATOR.batch_size,\n","       epochs=STEPS,\n","       batch_size=BATCH_SIZE, \n","       verbose=1,\n","       callbacks=[ModelCheckpoint(f'./Checkpoints/FC+OCFakeDectVAE/best_weights',\n","                                  monitor='val_auc', \n","                                  mode='max'\n","                                  verbose=1, \n","                                  save_best_only=True,\n","                                  save_weights_only=True)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohs32YdhOjrF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLE-Ww4Y37x2"},"source":["# # Load all training data, takes a very long time (3hrs)\n","# training_data = []\n","# for i in tqdm(range(TRAIN_GENERATOR.n//BATCH_SIZE+1)):\n","#     (x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), VALIDATION_GENERATOR.next()\n","#     training_data.extend(np.concatenate([x_train, x_test], axis=0)) \n","\n","# vae.fit(training_data,\n","#         epochs=100,\n","#         batch_size=2*BATCH_SIZE,\n","#         verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIrOs7aEqXMs"},"source":["# # VERY hacky test to see if the model is actually working\n","# # Purposefully overfit to a single batch of data and train for 1000 epochs on just that one batch\n","# (x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), VALIDATION_GENERATOR.next()\n","# training_data = np.concatenate([x_train, x_test], axis=0)\n","# vae.fit(training_data,\n","#         epochs=1000,\n","#         batch_size=2*BATCH_SIZE,\n","#         verbose=1)\n","\n","# for x in x_test[:10]:\n","#     X = np.expand_dims(x, axis=0)\n","#     Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","#     X_prime = vae.decoder.predict(Z)\n","#     face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","#     axes[0].imshow(X.squeeze())\n","#     axes[1].imshow(face)\n","#     fig.tight_layout()\n"],"execution_count":null,"outputs":[]}]}