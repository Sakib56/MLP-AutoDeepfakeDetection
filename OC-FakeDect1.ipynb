{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"OC-FakeDect1","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gU6tDeTCASMt","executionInfo":{"status":"ok","timestamp":1616703415103,"user_tz":0,"elapsed":2464,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"f3a56036-dcb5-4b02-ca90-fb4e540dfa85"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lqetwe06ASM7","executionInfo":{"status":"ok","timestamp":1616703427007,"user_tz":0,"elapsed":14354,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import BinaryCrossentropy\n","from keras import backend as K\n","\n","# !pip install -U keras-tuner\n","# from kerastuner.tuners import RandomSearch, Hyperband\n","# from kerastuner.engine.hypermodel import HyperModel\n","# from kerastuner.engine.hyperparameters import HyperParameters\n","# from kerastuner import Objective\n","\n","import Models.OCFakeDectVAE as OriginalOCFakeDectVAE"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dqaubd73ASM-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616703430303,"user_tz":0,"elapsed":17642,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"c495b135-6a94-421f-df13-20731b26989f"},"source":["# Check GPU available\n","%tensorflow_version 2.x\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZGWBPcE9ASNM","executionInfo":{"status":"ok","timestamp":1616703430304,"user_tz":0,"elapsed":17633,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 100, 100, 3\n","EPOCHS = 10\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 192\n","VALIDATION_SPLIT = 0.2\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd', 'avg'}\n","DF_TYPE = 'avg'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkC6WEcdASNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616703430809,"user_tz":0,"elapsed":18130,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"c4323333-5801-46de-fdf8-905efd6b6a57"},"source":["# We are only using one class (OC), reals... But we test on reals and fakes\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-OC' \n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'input', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'input', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 4502 images belonging to 1 classes.\n","Found 1125 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTUOyg8zWkg8","executionInfo":{"status":"ok","timestamp":1616703430814,"user_tz":0,"elapsed":18124,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Define callbacks e.g. Early Stopping\n","\n","EARLY_STOP = EarlyStopping(monitor='reconstruction_loss',\n","                           patience=1,\n","                           mode='min',\n","                           verbose=1,\n","                           restore_best_weights=True)\n","\n","# Define Model OCFakeDect1\n","vae = OriginalOCFakeDectVAE.OCFakeDect1()\n","vae.compile(optimizer=Adam())"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLYtSY4bnlhA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3ec632b-9cef-4042-b86f-f7ca1054bc86"},"source":["# Trains for full epochs, also very slow (30 mins per epoch on OC)\n","STEPS = TRAIN_GENERATOR.n//BATCH_SIZE+1\n","for _ in tqdm(range(EPOCHS)):\n","    for _ in tqdm(range(STEPS)):\n","        vae.fit(np.concatenate([TRAIN_GENERATOR.next()[0], VALIDATION_GENERATOR.next()[0]], axis=0),\n","                epochs=STEPS,\n","                batch_size=2*BATCH_SIZE,\n","                verbose=1,\n","                callbacks=[EARLY_STOP])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]\n","  0%|          | 0/563 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/563\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"igjOMUGwkdFs"},"source":["# Plot 5 images from test set\n","# for (x_train, _) in TRAIN_GENERATOR.next()[:5]:\n","#     X = np.expand_dims(x_train, axis=0)\n","#     Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","#     X_prime = vae.decoder.predict(Z)\n","#     face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","#     axes[0].imshow(X.squeeze())\n","#     axes[1].imshow(face)\n","#     fig.tight_layout()\n","\n","for (x_test, _) in VALIDATION_GENERATOR.next()[:5]:\n","    X = np.expand_dims(x_test, axis=0)\n","    Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","    X_prime = vae.decoder.predict(Z)\n","    face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","    axes[0].imshow(X.squeeze())\n","    axes[1].imshow(face)\n","    fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KlJGN8KyEBT"},"source":["# Re-define test generators for training the nerual net (since we are considering both classes now)\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30' \n","TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test' \n","\n","TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                    subset = 'training',\n","                                                    seed = DATA_GENERATOR_SEED,\n","                                                    follow_links = True)\n","\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                         batch_size = BATCH_SIZE,\n","                                                         class_mode = 'binary', \n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                         subset = 'validation',\n","                                                         seed = DATA_GENERATOR_SEED)\n","\n","TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0)\n","TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\n","                                                  batch_size = BATCH_SIZE,\n","                                                  class_mode = 'binary', \n","                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),                                \n","                                                  seed = DATA_GENERATOR_SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vqxqDa7yI0Zw"},"source":["# Freeze the layers for the encoder, since now we will only train the dence layers at the end\n","for layer in vae.encoder.layers:\n","    layer.trainable = False\n","\n","# Add simple neural network at end of encoder (AFTER encoder(and decoder) has been trained on OC)\n","_, _, x = vae.encoder.output\n","x = layers.Flatten()(x)\n","x = layers.Dense(1, activation = 'sigmoid')(x)\n","\n","FC = Model(vae.encoder.input, x, name=\"FC\")\n","FC.compile(optimizer = SGD(),\n","           loss = BinaryCrossentropy(),\n","           metrics = [metrics.BinaryAccuracy(name = 'acc'),\n","                      metrics.AUC(name = 'auc'),\n","                      metrics.FalsePositives(name = 'fp')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXilOj2gLOvh"},"source":["FC.fit(TRAIN_GENERATOR, \n","       steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size\n","       validation_data = VALIDATION_GENERATOR,\n","       validation_steps = TEST_GENERATOR.n//TEST_GENERATOR.batch_size,\n","       epochs=STEPS,\n","       batch_size=BATCH_SIZE, \n","       verbose=1,\n","       callbacks=[ModelCheckpoint(f'./Checkpoints/FC+OCFakeDectVAE/best_model',\n","                                  monitor='val_auc', \n","                                  mode='max'\n","                                  verbose=1, \n","                                  save_best_only=True)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLE-Ww4Y37x2"},"source":["# # Load all training data, takes a very long time (3hrs)\n","# training_data = []\n","# for i in tqdm(range(TRAIN_GENERATOR.n//BATCH_SIZE+1)):\n","#     (x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), VALIDATION_GENERATOR.next()\n","#     training_data.extend(np.concatenate([x_train, x_test], axis=0)) \n","\n","# vae.fit(training_data,\n","#         epochs=100,\n","#         batch_size=2*BATCH_SIZE,\n","#         verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIrOs7aEqXMs"},"source":["# # VERY hacky test to see if the model is actually working\n","# # Purposefully overfit to a single batch of data and train for 1000 epochs on just that one batch\n","# (x_train, _), (x_test, _) = TRAIN_GENERATOR.next(), VALIDATION_GENERATOR.next()\n","# training_data = np.concatenate([x_train, x_test], axis=0)\n","# vae.fit(training_data,\n","#         epochs=1000,\n","#         batch_size=2*BATCH_SIZE,\n","#         verbose=1)\n","\n","# for x in x_test[:10]:\n","#     X = np.expand_dims(x, axis=0)\n","#     Z_mean, Z_log_var, Z = vae.encoder.predict(X)\n","#     X_prime = vae.decoder.predict(Z)\n","#     face = np.array(X_prime.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)*255, dtype=np.uint8)\n","#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 5))\n","#     axes[0].imshow(X.squeeze())\n","#     axes[1].imshow(face)\n","#     fig.tight_layout()\n"],"execution_count":null,"outputs":[]}]}