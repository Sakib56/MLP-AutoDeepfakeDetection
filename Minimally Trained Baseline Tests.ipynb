{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Minimally Trained Baseline Tests","provenance":[{"file_id":"1UQUnqyHrzSZJr9H0Vi2mWUh-iQhbgTtv","timestamp":1617123690298}],"collapsed_sections":[],"authorship_tag":"ABX9TyP+T4MGhnQ+bdc0EXwDUSgq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"K7DxFXyRUNPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617178892376,"user_tz":-60,"elapsed":2428,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"25a288a6-7a4a-48ba-ce81-41d029f1dde4"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MLP-DeepfakeDetection-VariationalAutoencoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7W8i8xxtURw5","executionInfo":{"status":"ok","timestamp":1617178896079,"user_tz":-60,"elapsed":6100,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import binary_crossentropy\n","from keras import backend as K\n","\n","try:\n","    import face_recognition\n","except ModuleNotFoundError:\n","    !pip install face_recognition\n","\n","from Util import pipeline\n","from Baseline.classifiers import *"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6iN8C_aMd6Q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a07ea9ba-3ede-4c1c-b994-6e9e59602f1e"},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 256, 256, 3\n","EPOCHS = 100\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 128\n","VALIDATION_SPLIT = 0.2\n","\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd', 'avg'}\n","for DF_TYPE in ['diff', 'avg', 'rnd'][::-1]:\n","    TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test'\n","\n","    TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","    TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                        batch_size = BATCH_SIZE,\n","                                                        class_mode = 'binary', \n","                                                        target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                        subset = 'training',\n","                                                        seed = DATA_GENERATOR_SEED,\n","                                                        follow_links = True)\n","\n","    VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","    VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                             batch_size = BATCH_SIZE,\n","                                                             class_mode = 'binary', \n","                                                             target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                             subset = 'validation',\n","                                                             seed = DATA_GENERATOR_SEED,\n","                                                             follow_links = True)\n","\n","    # Train MesoInception4 w/ F2F weights\n","    TEST_MODEL = MesoInception4().model\n","    TEST_MODEL.compile(optimizer = TEST_MODEL.optimizer,\n","                       loss = TEST_MODEL.loss,\n","                       metrics = TEST_MODEL.metrics + [metrics.BinaryAccuracy(name = 'acc'),\n","                                                       metrics.AUC(name = 'auc'),\n","                                                       metrics.FalsePositives(name = 'fp')])\n","    \n","    WEIGHTS_PATH = './Baseline/weights/MesoInception_F2F.h5'\n","    TEST_MODEL.load_weights(WEIGHTS_PATH) \n","\n","    # Make last layer trainable\n","    for layer in TEST_MODEL.layers:\n","        layer.trainable = False\n","    TEST_MODEL.layers[-1].trainable = True\n","\n","    train_gen_list = list(TRAIN_GENERATOR.classes)\n","    val_gen_list = list(VALIDATION_GENERATOR.classes)\n","\n","    train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\n","    val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\n","\n","    pos = train_pos + val_pos\n","    neg = train_neg + val_neg\n","    total = pos + neg\n","\n","    weight_for_0 = (1 / neg)*(total)/2.0 \n","    weight_for_1 = (1 / pos)*(total)/2.0\n","\n","    CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\n","\n","    EARLY_STOP = EarlyStopping(monitor='val_auc',\n","                            patience=EPOCHS//20,\n","                            mode='max',\n","                            verbose=1,\n","                            restore_best_weights=True)\n","\n","    HISTORY = TEST_MODEL.fit(TRAIN_GENERATOR,\n","                            steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size,\n","                            validation_data = VALIDATION_GENERATOR,\n","                            validation_steps = VALIDATION_GENERATOR.n//VALIDATION_GENERATOR.batch_size,\n","                            epochs = EPOCHS,\n","                            verbose = 1,\n","                            class_weight = CLASS_WEIGHT,\n","                            callbacks = [EARLY_STOP])\n","\n","    weight_name = WEIGHTS_PATH.split('_')[-1].replace('.h5', '')\n","    pipeline.evaluate_model(TEST_MODEL = TEST_MODEL,\n","                            EXPERIMENT_NAME = f'Minimally Trained MesoInception4 on {DF_TYPE} with {weight_name}',\n","                            TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test',\n","                            WEIGHTS_PATH = '',\n","                            HISTORY = HISTORY)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 15711 images belonging to 2 classes.\n","Found 3927 images belonging to 2 classes.\n","Epoch 1/100\n","107/122 [=========================>....] - ETA: 19:41 - loss: 0.3153 - acc: 0.5490 - auc: 0.5129 - fp: 258.1682"],"name":"stdout"}]}]}